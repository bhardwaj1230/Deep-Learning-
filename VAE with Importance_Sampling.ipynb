{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.datasets import utils\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.modules import upsampling\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "#import tensorflow as tf\n",
    "\n",
    "def get_data_loader(dataset_location, batch_size):\n",
    "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
    "    # start processing\n",
    "    def lines_to_np_array(lines):\n",
    "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
    "    splitdata = []\n",
    "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
    "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
    "        filepath = os.path.join(dataset_location, filename)\n",
    "        utils.download_url(URL + filename, dataset_location, filename = filename, md5=None)\n",
    "        with open(filepath) as f:\n",
    "            lines = f.readlines()\n",
    "        x = lines_to_np_array(lines).astype('float32')\n",
    "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
    "        # pytorch data loader\n",
    "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
    "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\", pin_memory=True)\n",
    "        splitdata.append(dataset_loader)\n",
    "    return splitdata\n",
    "\n",
    "epochs = 20\n",
    "bs = 128\n",
    "\n",
    "train, valid, test = get_data_loader(\"binarized_mnist\", bs)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "for x in train:\n",
    "    plt.imshow(x[0, 0])\n",
    "    break\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=256):\n",
    "        return input.view(input.size(0), size, 1, 1)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "  \n",
    "    def __init__(self, image_channels=1, h_dim=256, z_dim=100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Q(z|X) -- encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 256, kernel_size=5),\n",
    "            nn.ELU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        # P(X|z) -- decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            UnFlatten(),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 64, kernel_size= 5, padding= 4),\n",
    "            nn.ELU(),\n",
    "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=2),\n",
    "            nn.ELU(),\n",
    "            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), #, align_corners=True\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(16, image_channels, kernel_size = 3, padding = 2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "      \n",
    "        \"\"\"std = logvar.mul(0.5).exp_()\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\"\"\"\n",
    "        eps = torch.randn(mu.size()).cuda()\n",
    "        z = eps.mul(logvar.mul(0.5).exp_()).add_(mu)\n",
    "          \n",
    "        logq_xz = torch.distributions.MultivariateNormal(mu,  torch.eye(100).cuda())\n",
    "        q_xz = logq_xz.log_prob(z)\n",
    "        \n",
    "        log_p_z = torch.distributions.MultivariateNormal(torch.zeros(100).cuda(), torch.eye(100).cuda())\n",
    "        p_z = log_p_z.log_prob(z)\n",
    "                \n",
    "        return z, q_xz, p_z\n",
    "\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z, q_xz, p_z = self.reparameterize(mu, logvar)\n",
    "        return z, q_xz, p_z, mu, logvar\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        h = self.encoder(x)\n",
    "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
    "        z_decoder = self.fc3(z)\n",
    "        decoder = self.decoder(z_decoder)\n",
    "        \n",
    "        return decoder, mu, logvar\n",
    "      \n",
    "    def imp_sample(self, x, h):\n",
    "        \n",
    "        z, q_xz, p_z, mu, logvar = self.bottleneck(h)\n",
    "        \n",
    "        z_decoder = self.fc3(z)\n",
    "        decoder = self.decoder(z_decoder)\n",
    "        \n",
    "        log_p_xz = torch.distributions.Bernoulli(decoder.view(decoder.size(0),784))\n",
    "        p_xz = log_p_xz.log_prob(x.view(x.size(0),784))\n",
    "        \n",
    "        return p_xz, q_xz, p_z\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/bhardwas/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data :  Epoch[1/20] ELBO: -96.045 ,BCE: 82.138 ,KLD: 13.907\n",
      "Training Data :  Epoch[2/20] ELBO: -80.444 ,BCE: 66.504 ,KLD: 13.940\n",
      "Training Data :  Epoch[3/20] ELBO: -73.830 ,BCE: 59.252 ,KLD: 14.578\n",
      "Training Data :  Epoch[4/20] ELBO: -68.884 ,BCE: 54.017 ,KLD: 14.867\n",
      "Training Data :  Epoch[5/20] ELBO: -60.572 ,BCE: 46.040 ,KLD: 14.532\n",
      "Training Data :  Epoch[6/20] ELBO: -66.402 ,BCE: 50.447 ,KLD: 15.955\n",
      "Training Data :  Epoch[7/20] ELBO: -62.277 ,BCE: 46.363 ,KLD: 15.915\n",
      "Training Data :  Epoch[8/20] ELBO: -59.959 ,BCE: 44.578 ,KLD: 15.381\n",
      "Training Data :  Epoch[9/20] ELBO: -61.027 ,BCE: 45.452 ,KLD: 15.575\n",
      "Training Data :  Epoch[10/20] ELBO: -63.458 ,BCE: 47.295 ,KLD: 16.163\n",
      "Training Data :  Epoch[11/20] ELBO: -63.981 ,BCE: 47.240 ,KLD: 16.741\n",
      "Training Data :  Epoch[12/20] ELBO: -58.973 ,BCE: 43.043 ,KLD: 15.931\n",
      "Training Data :  Epoch[13/20] ELBO: -61.327 ,BCE: 45.105 ,KLD: 16.221\n",
      "Training Data :  Epoch[14/20] ELBO: -59.745 ,BCE: 43.539 ,KLD: 16.206\n",
      "Training Data :  Epoch[15/20] ELBO: -58.883 ,BCE: 42.604 ,KLD: 16.278\n",
      "Training Data :  Epoch[16/20] ELBO: -62.263 ,BCE: 45.529 ,KLD: 16.734\n",
      "Training Data :  Epoch[17/20] ELBO: -62.486 ,BCE: 46.149 ,KLD: 16.337\n",
      "Training Data :  Epoch[18/20] ELBO: -58.398 ,BCE: 42.474 ,KLD: 15.924\n",
      "Training Data :  Epoch[19/20] ELBO: -58.613 ,BCE: 42.352 ,KLD: 16.261\n",
      "Training Data :  Epoch[20/20] ELBO: -56.946 ,BCE: 41.147 ,KLD: 15.799\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "model = VAE().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss(reduction = \"sum\").cuda()\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    ## E[log P(X|z)]\n",
    "    \n",
    "    BCE = criterion(recon_x, x)\n",
    "    KLD = - 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp() )\n",
    "    return BCE + KLD, BCE, KLD\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, (images) in enumerate(train):\n",
    "        #optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_images, mu, logvar = model(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
    "                            epochs, -loss/bs, bce/bs, kld/bs)\n",
    "    print(\"Training Data : \", to_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance Sampling Function:\n",
    "\n",
    "def importance_sampling(model, data):\n",
    "    #Input as our trained model and data\n",
    "  \n",
    "    ip_loss = []\n",
    "    count = 0\n",
    "    #Setting the model parameters to no_grad\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for idx, (images) in enumerate(valid):\n",
    "        images = images.to(device)\n",
    "        count += 1\n",
    "        #Calling model to get the output from encoder\n",
    "        h = model.encoder(images.view(images.size(0),1,28,28))\n",
    "        h = h.view(images.size(0),256)\n",
    "\n",
    "        ip_sample = []\n",
    "\n",
    "        for k in range(200):\n",
    "            #Calling model to get output of our densities :\n",
    "            p_xz, q_xz, p_z = model.imp_sample(images, h)\n",
    "            #Summing over 784 dimention and the dimention we will have (1XBatch_Size)\n",
    "            p_xz = torch.sum(p_xz,dim=1)\n",
    "            #Importance Sampling calculation with LogSumExp trick:\n",
    "            out = p_xz - q_xz + p_z\n",
    "            log_weight = out - torch.max(out, 0)[0]\n",
    "            weight = torch.exp(log_weight)\n",
    "            weight = weight / torch.sum(weight, 0)\n",
    "            loss = torch.mean(torch.sum(weight * (p_z + p_xz - q_xz), 0))\n",
    "            ip_sample.append(loss)\n",
    "\n",
    "        ip_loss.append(torch.sum(torch.stack(ip_sample))/bs)\n",
    "\n",
    "    print(\"Importance Sampling over mini batch -\", count,' : ' , torch.stack(ip_loss))\n",
    "\n",
    "    log_likelihood_estimate = torch.mean(torch.stack(ip_loss))\n",
    "    print('log-likelihood  estimate :', log_likelihood_estimate)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance Sampling over mini batch - 79  :  tensor([-53.0373, -39.6375, -42.0156, -45.4993, -43.2120, -39.7358, -50.2935,\n",
      "        -52.7791, -49.9681, -47.0958, -52.0168, -43.4983, -44.4474, -45.6429,\n",
      "        -42.7070, -42.4412, -45.6604, -48.0044, -42.9745, -47.7442, -46.1955,\n",
      "        -48.5450, -47.9398, -49.5970, -46.7224, -43.6381, -46.3858, -45.7736,\n",
      "        -46.1605, -44.1194, -42.1705, -48.9098, -45.9725, -43.3371, -42.3633,\n",
      "        -40.1183, -46.3247, -43.2202, -44.9085, -47.2767, -48.7591, -41.9616,\n",
      "        -47.2108, -42.1973, -41.6795, -41.4401, -40.9675, -45.4725, -44.3390,\n",
      "        -49.2932, -48.3470, -45.8876, -35.1705, -44.6851, -48.6321, -47.3355,\n",
      "        -44.9034, -43.3303, -45.2567, -47.7691, -42.3350, -50.9472, -43.4320,\n",
      "        -44.1024, -45.1459, -49.2735, -46.8572, -40.4301, -46.7594, -45.4955,\n",
      "        -44.2671, -43.6105, -42.2646, -46.1439, -49.0317, -44.5678, -43.1247,\n",
      "        -49.4768, -92.1708], device='cuda:0')\n",
      "log-likelihood  estimate : tensor(-45.9768, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Importance Sampling on Validation Data:\n",
    "importance_sampling(model, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance Sampling over mini batch - 79  :  tensor([-53.2666, -39.6112, -42.0173, -45.0696, -42.7885, -39.3289, -50.2789,\n",
      "        -52.5768, -50.1204, -47.3126, -51.4464, -43.7340, -44.2706, -46.3034,\n",
      "        -42.7663, -42.2453, -45.8034, -47.9994, -43.1152, -47.3775, -46.3774,\n",
      "        -48.9510, -47.6278, -50.0038, -46.5382, -43.5363, -46.5026, -45.6286,\n",
      "        -45.8510, -44.3316, -42.0889, -48.5721, -45.6009, -43.2220, -41.8239,\n",
      "        -39.9657, -46.6021, -43.0379, -44.8822, -47.2276, -49.2708, -41.3384,\n",
      "        -48.0132, -42.6075, -41.1648, -41.6543, -41.3515, -45.6582, -44.9995,\n",
      "        -48.8655, -48.8445, -45.2723, -34.1606, -45.0158, -48.3008, -47.6436,\n",
      "        -45.0193, -43.4447, -45.0337, -47.7312, -42.3400, -50.9683, -43.3457,\n",
      "        -43.8593, -44.5975, -49.5735, -46.5705, -40.6795, -47.0243, -45.8740,\n",
      "        -44.4704, -43.6746, -42.3586, -45.8282, -49.6287, -45.2142, -42.7317,\n",
      "        -49.6860, -91.7219], device='cuda:0')\n",
      "log-likelihood  estimate : tensor(-45.9663, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Importance Sampling on Test Data:\n",
    "importance_sampling(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
      "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running Validation :\n",
    "epochs = 1\n",
    "bs = 10000\n",
    "\n",
    "train, valid, test = get_data_loader(\"binarized_mnist\", bs)\n",
    "\n",
    "len(valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data :  Epoch[1/1] ELBO: -95.835 ,BCE: -69.644 ,KLD: 26.191\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (images) in enumerate(valid):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        recon_images, mu, logvar = model(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "    \n",
    "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
    "                            epochs, -loss/bs, -bce/bs, kld/bs)\n",
    "    print(\"Validation Data : \", to_print)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data :  Epoch[1/1] ELBO: -95.108 ,BCE: -69.049 ,KLD: 26.060\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (images) in enumerate(test):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        recon_images, mu, logvar = model(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "    \n",
    "    to_print = \"Epoch[{}/{}] ELBO: {:.3f} ,BCE: {:.3f} ,KLD: {:.3f}\".format(epoch+1, \n",
    "                            epochs, -loss/bs, -bce/bs, kld/bs)\n",
    "    print(\"Test Data : \", to_print)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
